{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import skimage\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from modules.dataset import FullLengthVideosDataset\n",
    "from modules.models.LRCNN import SeqRecurrentCNN\n",
    "from modules.metrics import MulticlassAccuracy\n",
    "from modules.utils import set_random_seed\n",
    "\n",
    "rescale_factor = 1.0\n",
    "random_seed = 42\n",
    "\n",
    "set_random_seed(random_seed)\n",
    "save_dir = \"../models/Full_LRCNN/\"\n",
    "full_path = \"/tmp2/itsmystyle/h4_data/FullLengthVideos/\"\n",
    "train_video_path = os.path.join(full_path, 'videos', 'train')\n",
    "train_label_path = os.path.join(full_path, 'labels', 'train')\n",
    "valid_video_path = os.path.join(full_path, 'videos', 'valid')\n",
    "valid_label_path = os.path.join(full_path, 'labels', 'valid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "lr = 2e-4\n",
    "accumulate_gradient = 8\n",
    "\n",
    "model = SeqRecurrentCNN()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-5)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "metric = MulticlassAccuracy()\n",
    "\n",
    "writer = SummaryWriter(os.path.join(save_dir, \"train_logs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = FullLengthVideosDataset(train_video_path, train_label_path, length=80, overlap=20, sorting=True)\n",
    "valid_set = FullLengthVideosDataset(valid_video_path, valid_label_path, length=100, overlap=0, sorting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=4, num_workers=32, shuffle=True, collate_fn=train_set.collate_fn)\n",
    "valid_loader = DataLoader(valid_set, batch_size=4, num_workers=32, shuffle=False, collate_fn=valid_set.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_one_epoch(epoch, iters):\n",
    "    model.train()\n",
    "    \n",
    "    trange = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Epoch {}\".format(epoch))\n",
    "    \n",
    "    metric.reset()\n",
    "    batch_loss = 0.0\n",
    "    \n",
    "    for idx, batch in trange:\n",
    "        iters += 1\n",
    "\n",
    "        frames = batch[\"frames\"].to(device)\n",
    "        frames_len = batch[\"frames_len\"]\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        preds = model(frames, frames_len)\n",
    "\n",
    "        # calculate loss and update weights\n",
    "        loss = criterion(preds.view(-1, preds.shape[-1]), labels.view(-1)) / accumulate_gradient\n",
    "        if idx % accumulate_gradient == 0:\n",
    "            optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if (idx + 1) % accumulate_gradient == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "        # update metric\n",
    "        metric.update(preds.view(-1, preds.shape[-1]).cpu(), labels.view(-1).cpu())\n",
    "\n",
    "        # update loss\n",
    "        batch_loss += loss.item() * accumulate_gradient\n",
    "        writer.add_scalars(\n",
    "            \"Loss\", {\"iter_loss\": loss.item(), \"avg_loss\": batch_loss / (idx + 1)}, iters,\n",
    "        )\n",
    "\n",
    "        # update tqdm\n",
    "        trange.set_postfix(\n",
    "            loss=batch_loss / (idx + 1), **{metric.name: metric.print_score()}\n",
    "        )\n",
    "\n",
    "    if (idx + 1) % accumulate_gradient != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return batch_loss / (idx + 1), iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_one_epoch(val_iters, best_accuracy):\n",
    "    model.eval()\n",
    "\n",
    "    trange = tqdm(enumerate(valid_loader), total=len(valid_loader), desc=\"Valid\")\n",
    "\n",
    "    metric.reset()\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in trange:\n",
    "            val_iters += 1\n",
    "\n",
    "            frames = batch[\"frames\"].to(device)\n",
    "            frames_len = batch[\"frames_len\"]\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            preds = model(frames, frames_len)\n",
    "            loss = criterion(preds.view(-1, preds.shape[-1]), labels.view(-1))\n",
    "\n",
    "            # update loss\n",
    "            batch_loss += loss.item()\n",
    "            writer.add_scalars(\n",
    "                \"Val_Loss\",\n",
    "                {\"iter_loss\": loss.item(), \"avg_loss\": batch_loss / (idx + 1)},\n",
    "                val_iters,\n",
    "            )\n",
    "\n",
    "            # update metric\n",
    "            metric.update(preds.view(-1, preds.shape[-1]).cpu(), labels.view(-1).cpu())\n",
    "\n",
    "            # update tqdm\n",
    "            trange.set_postfix(\n",
    "                loss=batch_loss / (idx + 1), **{metric.name: metric.print_score()}\n",
    "            )\n",
    "\n",
    "        # save best acc model\n",
    "        if metric.get_score() > best_accuracy:\n",
    "            print(\"Best model saved!\")\n",
    "            best_accuracy = metric.get_score()\n",
    "            _loss = batch_loss / (idx + 1)\n",
    "            torch.save(\n",
    "                model.state_dict(), os.path.join(\n",
    "                    save_dir,\n",
    "                    \"model_best_{:.5f}_{:.5f}.pth.tar\".format(best_accuracy, _loss),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return batch_loss / (idx + 1), best_accuracy, val_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = -1\n",
    "val_iters = -1\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    loss, iters = _run_one_epoch(epoch, iters)\n",
    "    \n",
    "    loss, best_accuracy, val_iters = _eval_one_epoch(val_iters, best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
